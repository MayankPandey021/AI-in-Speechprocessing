## Question 1
import librosa
import soundfile as sf
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import Audio, display

# Loading audio file
y, sr = librosa.load(r"Desktop\Audio.wav")

y_trim, index = librosa.effects.trim(y)

sf.write('trimmed_audio.wav', y_trim, sr)

plt.figure(figsize=(16, 4))
plt.plot(y)
plt.title('Original Speech')
plt.show()
plt.figure(figsize=(16, 4))
plt.plot(y_trim)
plt.title('Trimmed Speech')
plt.show()

D_original = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
librosa.display.specshow(D_original, sr=sr, x_axis='time', y_axis='mel')
plt.title('Mel Spectrogram of Original Speech')
plt.colorbar(format='%+2.0f dB')
plt.show()

D_trimmed = librosa.amplitude_to_db(np.abs(librosa.stft(y_trim)), ref=np.max)
librosa.display.specshow(D_trimmed, sr=sr, x_axis='time', y_axis='mel')
plt.title('Mel Spectrogram of Trimmed Speech')
plt.colorbar(format='%+2.0f dB')
plt.show()

## Question 2
import librosa
import soundfile as sf
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import Audio, display

y, sr = librosa.load(r"Desktop\Audio.wav")

intervals = librosa.effects.split(y, top_db=50)

for i, interval in enumerate(intervals):
    start, end = interval
    y_split = y[start:end]

    sf.write(f'split_audio_{i}.wav', y_split, sr)

    display(Audio(data=y_split, rate=sr))

    plt.figure(figsize=(12, 4))
    plt.plot(y_split)
    plt.title(f'Waveform of Segment {i+1}')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.grid(True)
    plt.show()

    plt.figure(figsize=(12, 6))
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y_split)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='mel')
    plt.title(f'Mel Spectrogram of Segment {i+1}')
    plt.xlabel('Time (s)')
    plt.ylabel('Mel Frequency')
    plt.colorbar(format='%+2.0f dB')
    plt.show()
